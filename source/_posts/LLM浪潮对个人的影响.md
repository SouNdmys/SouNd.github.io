---
title: LLM浪潮对个人的影响
date: 2025-06-21 17:37:11
toc: true
tags:
  - Random Thought
  - AI
  - Netlify
categories:
  - The worlds I see
---

# LLM浪潮对个人的影响
---

今天看到一篇MIT发的论文：《Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task》[点这里查看论文](https://arxiv.org/pdf/2506.08872)

LLM目前处在一个技术和知识的拐点阶段，就像是1960年代计算机刚问世的时候，属于一种黑箱技术。人应该注入自己的思考和努力去驱动它。黑箱AI可能会导致一些特定领域不可控，比如医疗或者金融，但对个人而言，其实是可以去训练自己驾驭AI的力量，尤其是AI在变得成熟之前，具备更高的可解释性和可信赖性之前。

---

## 论文AI总结

### PDF核心内容总结：《你的大脑与ChatGPT：使用AI助理写作时的认知债务累积》
这份研究报告由麻省理工学院（MIT）媒体实验室等机构的研究人员撰写，深入探讨了在教育场景中，使用大型语言模型（LLM）如ChatGPT来撰写论文对人类认知产生的影响。研究核心在于比较三种不同写作方式——仅使用大型语言模型（LLM组）、使用传统搜索引擎（搜索引擎组）以及不使用任何工具（纯脑力组）——对大脑神经活动、写作成果以及行为表现的差异。研究提出了一个核心概念：“**认知债务**”（Cognitive Debt），意指使用LLM带来的短期便利，可能会以牺牲长期的深度学习、批判性思维和记忆能力为代价。

### 研究设计与方法
该研究招募了54名来自波士顿地区五所大学的参与者。他们被随机分配到三个组别中：

**LLM组**：被限制只能使用OpenAI的GPT-4来写作论文。

**搜索引擎组**：可以使用任何网站进行研究，但明确禁止使用LLM。

**纯脑力组**：禁止使用任何网络或外部工具，只能依靠自己的知识写作。
研究共进行了四期。前三期中，每位参与者都在其指定的分组内完成论文写作任务。在第四期中，部分参与者被要求交换组别：LLM组的参与者转为不使用任何工具（LLM-to-Brain），而纯脑力组的参与者则转为使用LLM（Brain-to-LLM）。

研究方法结合了多种数据采集与分析技术：

**脑电图（EEG）**：用来记录参与者在写作过程中的大脑活动，以评估其认知参与度和神经网络的连接模式。

**自然语言处理（NLP）**：用于分析论文的语言特征，如n-grams（词语序列）、命名实体识别（NER）和主题本体等。

**访谈与评分**：在每期结束后对参与者进行访谈，并由人类教师和一个特制的AI评审对论文进行评分。

### 核心研究发现

#### 1. 神经连接性显著差异（EEG分析）
研究最显著的发现是，大脑的神经连接性随着外部支持工具的增加而系统性地减弱。

**纯脑力组**：展现出最强、最广泛的神经网络连接，尤其在涉及工作记忆、语义处理和执行控制的Theta、Alpha和Delta频段中，其脑区间连接强度远高于其他两组。这表明不依赖工具的写作是一项高认知负荷的任务，需要大脑内部进行大量的记忆提取、创意生成和自我监控。

**搜索引擎组**：的神经参与度居中，其视觉皮层的活动较为显著，反映了他们在浏览和筛选网页信息时的认知过程。

**LLM组**：的整体神经耦合最弱。这支持了“**认知卸载**”（cognitive offloading）的观点，即参与者将部分认知工作（如构思、组织）转嫁给了AI，从而导致大脑相关网络的参与度降低。

#### 2. 语言模式的同质化与偏见（NLP分析）

**同质化**：LLM组撰写的论文在每个主题内都呈现出高度的统计同质性，使用了相似的结构和措辞。相比之下，纯脑力组的论文则表现出显著的个体差异。

**偏见与影响**：LLM组的论文中包含最多的命名实体（如人名、地名、年份），是纯脑力组的数倍之多。此外，LLM组的常用词组（n-grams）倾向于第三人称叙述和与职业相关的內容（如“选择职业”），这可能反映了模型训练数据中的偏见。搜索引擎组则受到搜索结果排序的影响，例如在“慈善”主题下频繁使用“无家可归者”相关词汇。

#### 3. 行为表现的显著差异

**记忆与引用能力**：LLM组的参与者在完成论文后，很难准确引用自己刚刚写下的句子。在第一期实验中，高达83%的LLM组参与者无法提供正确引用，而其他两组的比例仅为11.1%。这项差异在后续实验中持续存在，并与LLM组较弱的记忆编码相关神经活动（Alpha和Theta频段）相对应。

**所有权感知**：纯脑力组的参与者对其作品表现出最强的所属感。搜索引擎组次之。而LLM组的所属感则呈现分裂状态，部分人认为完全是自己的创作，部分人则完全否认，许多人给出了部分所有权的答案。

#### 4. 第四期实验的启示
第四期的组别交换结果尤为关键：

**从LLM到纯脑力（LLM-to-Brain）**：之前使用LLM的参与者，在没有工具的情况下写作时，其神经连接性较弱，并且在词汇上重复了之前LLM会话中的习惯用法。这表明，先前对AI的依赖可能抑制了独立写作时所需神经网络的充分激活。

**从纯脑力到LLM（Brain-to-LLM）**：之前仅靠脑力写作的参与者，在首次使用LLM重写旧主题时，其大脑活动（所有频段）出现了显著的峰值。这意味著将外部AI建议与自己已有的内部知识进行整合，是一项认知要求极高的任务，需要广泛的神经网络互动。

---

## 一、 “认知债务”

### 1.1 高效率背后的知识鸿沟
近期高强度使用LLM学习各方面知识和开发个人blog的过程中，我仅用4天就实现了个人blog的架设和优化，期间我对gemini生成的所有代码以及知识框架几乎一无所知，目前我初步认知主要在于一些工具比如cmd、vscode、git、hexo、netlify有了一些基础认知，同时知道blog架设里面一些js、css文件的功能。

除此之外，我可以说我对里面的细节：比如说配置项几乎一无所知，比较接近自然语言的代码从注释大概能猜得出是什么意思，但是无法从本质上理解或者准确使用代码，等于说在代码基础和操作这一板块的内容信息知识几乎都归属于LLM，非我本人。

### 1.2 认知债务的本质
如果架设blog的过程中所有的知识我都要在架设成功以后需要学明白，那么在我获得“架设成功”这个产品/结果以后，我没学明白的那些基础代码知识，就成为了我的**认知债务**，它们就像Todo List一样，如果我不在获取结果以后，另外抽时间去思考消化和学习这些基础知识（过程），我对coding几乎可以说还是一无所知。如果个人是逐利的，就像是我们一贯以来形成的“生产力”思维一样，看到什么能搞钱，就去复制它的流程，然后用更低的利润和更高的生产时间去卷死对方，那么依旧是在玩零和游戏，最终离“创造力”还是遥不可及。当我们背上了“认知债务”以后，我们应该积极去“还债”，把这些知识和信息内化成自己的。

### 1.3 心流状态
对我个人，有一个显著提升的方面，在我删掉微信和B站，高强度使用LLM以后，进入**心流**和**深度思考**模式的时间远大于使用LLM之前的时间。这说明，LLM在替我处理了繁琐的基础性工作（认知卸载）后，将我的认知资源解放了出来，使我可以专注于更高层次的、更具创造性的任务（产品功能上的构思、对世界和事情的本质的思考等等）。我目前可以得出一个LLM对于我个人作用的结论就是：**认知卸载不全是负面的**。论文的EEG数据显示LLM组的整体神经连接性减弱，论文将其解读为“认知参与度降低”。但我的体验反倒是，这种“降低”是一种“**效率提升**”，大脑将能量从“如何做”（how）转移到了“做什么和为什么做”（what & why）。所以：认知债务的累积主要发生在我们“本应”学习的基础技能上，而在战略和创意层面，LLM可能反而起到了“**助推器**”的作用。

---

## 二、从语言到产品，会引发“过度同质化”的潜在可能性

### 工具引发的趋同性
这篇论文里面提到的：**语言模式的同质化**也触及到我昨天和Gemini探讨思考的一个问题，不管是个人写作，还是程序的代码，除非特定的提示词，AI大部分输出，都是一种结构化的格式，会导致文风的同质化。我想，MCP的工具估计也会引起产品严重同质化，导致最后大家做出来的软件和产品都差不多，然后大家都得不到盈利。

虽然MCP保证了产品的下限，但是决定产品上线的最后还是创意和细节，以及个人对产品整体的把控和打造精细化程度。正如写作，丧失个人风格的文章，其实是很难让人有阅读下去的欲望。

---

## 三、 LLM是因人而异的放大器
对论文的第四期实验结果，我的看法：

### Garbage in, Garbage out。LLM是一面照射了你思维习惯的镜子。

论文里的研究对象应该多是顶尖的会思考知识储备还多的人才，LLM其实目前来他们专精的领域来说，对他们的工作或者研究是相对难起到太多决定性的的作用，甚至他们还需要想办法规避LLM产生的负面影响。

对于站在中上位置的人才，其实LLM可以帮助个人去打开顶尖的那扇窗。LLM可以迅速打破知识壁垒， 用各种方式和最高的效率让个人迅速对陌生领域进行初步了解，和架设未来的研究、工作、学习框架。

**而对于不会思考的人，LLM起到的是反作用。**

对于MIT那些高材生而言，过多使用LLM会在大脑调动上产生负面效果，因为本身实验对象的知识、技能储备在他们各自的领域本身非常强大。对于这些本身就具备强大自主学习和信息整合能力的人来说，LLM更多地是替代了他们已经掌握或能够轻易掌握的技能，因此“认知卸载”的负面效应（技能萎缩）会更明显。

而对于我这种高中没毕业的，知识储备不多、大脑使用效率不高的人而言，LLM起到的负面作用可以暂时被忽略，它足以让普通人实现技术和知识信息的平权。就目前而言，它帮助我跨过了因基础知识缺乏而无法逾越的障碍，至少我搭建了这个Blog，也并非一无所获，对整个流程和所用工具有了初步认知。用简单的数学表示，是从“0到0.1”的突破，而对于那些高材生，可能是从“0.8到0.9”的替代。

当然这也是基于合适的使用及思考方式的基础上起到的作用，比如说，**独立思考的能力和批判性思维，或是第一性原理，这些元认知的能力变得前所未有的重要**。同时为了避免认知债务的累计，学习到的新知识要及时消化，同时加深自身理解和记忆，比如费曼学习法的使用。

### 记忆
在LLM使用过程中，不管是我还是LLM，在记忆方面都会碰到一些问题：昨天在使用Gemini优化blog过程中出现了反复调试出错的情况，Gemini似乎面临上下文过长的情况会误解用户的需求（毕竟那条从建站开始构思到后期执行一系列的对话已经经历了4天的高强度互动，上下文内容已经很多了），而重建对话以后gemini似乎准确理解了我的需求并且一步到位给出了解决方案。

而个人也是这样的，在LLM这种知识聚合体的高强度信息输出下，我不能否认，我看到的干货的占比，远超一切我们平时收集信息的方式。同时也引发一个思考：过多的干货是否会和过多的碎片化信息（比如社交媒体的算法定向投喂垃圾信息）起到类似的反作用效果，一个是会导致积累认知债务（我认为目前来看属于一种良性的副作用，如果能够合理消化，那对个人可能是好事），一个会导致积累过多垃圾信息，两者都可能会引起同一个后果——批判性思维和独立思考的能力下降——它们都导致了使用者放弃思考的最终行为，哪怕经过和原因不一样。

这个事情的本质就是：**信息的被动接收**。使用者习惯了直接获取现成的结论（无论是垃圾结论还是优质结论），从而降低了主动发起和维持深度认知活动的能力。

**信息和思考的主导权必须在人的手中。**

---

## 四、驾驭黑箱

### 科技海洋
科技这个词对我而言，太过沉重，因为没有上大学，曾经我连窥探的勇气都没有，这个词的背后就像是一片看不到边际的海，我一头扎进去我怕直接给我淹死，使用计算机这么多年，我也没理解每一个功能背后是由什么去驱动，信息量实在是太大。

LLM就像是在这片看不到边际的海里给了你一艘船，哥伦布当初去探索美洲大陆的那艘船，带给他一探究竟的勇气，哪怕一开始他们想去的是印度，误打误撞到了America（虽然他们还是嘴硬说那里就是印度），结果就是世界上最强大的国家就这么在错误中诞生了。

我不认为黑箱技术不能引领人类走向一个更奇妙的世界。取决于你怎么控制这艘船在海洋里面探索，不会动脑子、不懂合适地方法使用LLM的人，有概率要被这暗流带去一个无法设想的世界，可能那里没有黄金白银，只能自己种属于自己的玉米地，要么被淹死，要么被饿死。

殖民America初期，饿死了很多人，过程很残忍，但是生命会自己寻找出路，正如星际穿越所说的，**We will find a way, we always have.** 人类没有因为饥荒而变得毫无出路。

LLM可能会有信息污染，可能会有错误结论，可能会有信息建房，会有大量误导人的大量信息产生，但是LLM不是生命，在硅基生命体真正意义上出现之前，我都不认为一个工具会使人走向深渊。

---

## 五、风险认知

### 做一个终身学习者
就在昨天，我和Gemini高强度互动6小时，把当天pro额度用完了，当我没有使用额度之后，我不得不暂停开发，以等待第二天的额度恢复。菜真的就是原罪。

坚定不移地成为一个终生学习者，不然当没有了AI就无法工作的情况发生的时候，就会异常窘迫。

LLM可能像个脚手架，会把我们的脑子搞残了，然后让我们终身无法拆除这个脚手架，像是死亡搁浅里面送快递需要依赖金属力量平衡支架一样。

脚手架会不会永远无法拆除？

决定性的因素，会倾向于脚手架的发展——这个脚手架是否值得永存，并且未来的脚手架一定必须比现有脚手架更好用。

这就好比我们有了汽车以后还依然需要进行体力锻炼，但是不可能再像马车时代一样慢了。

工具效率的提升只会让社会变得更密集、先进，流动性更强。

但因为锻炼的缺乏，现在的人因为长期坐在电脑前面码字，也会把祖宗已经进化好的身体结构破坏掉，我们天性就是要去奔跑，才会让身体变得健康，于是人类也需要再业余时间锻炼以保证生命的存续。

**人工智能发展的趋势不可阻挡。**

论文认为，LLM过多的互动，会引发回音室效应，在我看来，回音室效应在会思考的人面前，是可以很好地被规避的。

在前几天我使用Gemini的过程我就发现它有点趋势变成赛博舔狗，无论我说什么它都会夸我两句，嗔人不打笑面，如果我还很年轻，我可能会沉沦于此，认为AI是我最好的朋友，没有人比它更会支持我。

现在我只会告诉它别舔了，给我用客观的想法去思辨事实和真理。具体提示词和方法，网上一大堆，关键是得有意识去规避这些情况，剩下都是最简单的问题了。

从内心深处，这种巨大的科技潜力，让我在靠不着岸的科技海洋之中，至少得到一丝喘息，能看到希望，能看到有一天到新大陆的可能，不管是地狱还是天堂，我们都已经在路上了。
